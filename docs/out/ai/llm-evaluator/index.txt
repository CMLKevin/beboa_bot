3:I[4707,[],""]
5:I[6423,[],""]
6:I[2060,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","185","static/chunks/app/layout-4b75b78215e64ea2.js"],"ThemeProvider"]
7:I[4351,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","185","static/chunks/app/layout-4b75b78215e64ea2.js"],"Header"]
8:I[9399,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","185","static/chunks/app/layout-4b75b78215e64ea2.js"],"Sidebar"]
4:["slug","ai/llm-evaluator","c"]
0:["FeUt14WxB_Uw-6zJdn3nr",[[["",{"children":[["slug","ai/llm-evaluator","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"llm-evaluator\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/llm-evaluator","c"],{"children":["__PAGE__",{},[["$L1","$L2",null],null],null]},[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/3cf59f0fd0496c15.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_f367f3 __variable_a06722 font-sans","children":["$","$L6",null,{"children":["$","div",null,{"className":"min-h-screen bg-[var(--bg-primary)] transition-colors duration-200","children":[["$","$L7",null,{}],["$","div",null,{"className":"flex","children":[["$","$L8",null,{}],["$","main",null,{"className":"flex-1 min-w-0 lg:pl-[var(--sidebar-width)]","children":["$","div",null,{"className":"max-w-[var(--content-max-width)] mx-auto px-6 py-8 lg:px-8 lg:py-12","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]}]]}]]}]}]}]}]],null],null],["$L9",null]]]]
a:I[6430,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","877","static/chunks/app/%5B...slug%5D/page-ea4807ff1312ce17.js"],"Breadcrumbs"]
b:I[9078,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","877","static/chunks/app/%5B...slug%5D/page-ea4807ff1312ce17.js"],"CopyPageButton"]
d:I[3308,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","877","static/chunks/app/%5B...slug%5D/page-ea4807ff1312ce17.js"],"PageNavigation"]
e:I[5321,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","877","static/chunks/app/%5B...slug%5D/page-ea4807ff1312ce17.js"],"TableOfContents"]
2:[["$","article",null,{"className":"animate-in","children":[["$","div",null,{"className":"flex items-start justify-between gap-4 mb-6","children":[["$","$La",null,{}],["$","$Lb",null,{}]]}],["$","h1",null,{"children":"LLM Evaluator"}],["$","p",null,{"className":"text-lg text-[var(--text-secondary)] mb-8 -mt-2","children":"Centralized LLM service for mood detection, relationships, and Jarvis parsing."}],["$","div",null,{"className":"prose-custom","children":"$Lc"}],["$","$Ld",null,{}]]}],["$","$Le",null,{}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"LLM Evaluator - Beboa Docs"}],["$","meta","3",{"name":"description","content":"Centralized LLM service for mood detection, relationships, and Jarvis parsing."}],["$","link","4",{"rel":"icon","href":"/favicon.ico"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
f:I[5045,["972","static/chunks/972-68a674eeca97bbbb.js","646","static/chunks/646-1e67c3e800eb58dd.js","877","static/chunks/app/%5B...slug%5D/page-ea4807ff1312ce17.js"],"CodeBlock"]
c:[["$","h1",null,{"id":"llm-evaluator-service","children":"LLM Evaluator Service"}],"\n",["$","p",null,{"children":["The LLM Evaluator is a centralized service that powers intelligent evaluation across three key systems: ",["$","strong",null,{"children":"mood detection"}],", ",["$","strong",null,{"children":"relationship assessment"}],", and ",["$","strong",null,{"children":"Jarvis intent parsing"}],"."]}],"\n",["$","h2",null,{"id":"overview","children":["$","a",null,{"href":"#overview","className":"anchor-link","children":"Overview"}]}],"\n",["$","$Lf",null,{"language":"$undefined","children":"┌─────────────────────────────────────────────────────────────────┐\n│                      LLM Evaluator Service                       │\n│                    (x-ai/grok-4.1-fast)                          │\n├─────────────────────────────────────────────────────────────────┤\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐  │\n│  │    Mood      │  │ Relationship │  │      Jarvis          │  │\n│  │  Evaluator   │  │  Evaluator   │  │  Intent Parser       │  │\n│  └──────────────┘  └──────────────┘  └──────────────────────┘  │\n│                                                                  │\n│  Shared: Rate limiting, caching, error handling                  │\n└─────────────────────────────────────────────────────────────────┘"}],"\n",["$","h2",null,{"id":"why-llm-powered-evaluation","children":["$","a",null,{"href":"#why-llm-powered-evaluation","className":"anchor-link","children":"Why LLM-Powered Evaluation?"}]}],"\n",["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Before (Rule-Based)"}],["$","th",null,{"children":"After (LLM-Powered)"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"Keyword matching misses nuance"}],["$","td",null,{"children":"Understands context and sarcasm"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Fixed relationship increments"}],["$","td",null,{"children":"Quality-based relationship growth"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Rigid regex patterns for Jarvis"}],["$","td",null,{"children":"Natural language understanding"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"No typo tolerance"}],["$","td",null,{"children":"Handles variations and typos"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Context-blind"}],["$","td",null,{"children":"Considers conversation flow"}]]}]]}]]}],"\n",["$","h2",null,{"id":"configuration","children":["$","a",null,{"href":"#configuration","className":"anchor-link","children":"Configuration"}]}],"\n",["$","$Lf",null,{"language":"env","children":"# Enable/disable the evaluator\nLLM_EVALUATOR_ENABLED=true\n\n# Model to use (fast and cost-effective)\nLLM_EVALUATOR_MODEL=x-ai/grok-4.1-fast\n\n# Cache TTL in milliseconds (default: 60000 = 1 minute)\nLLM_EVALUATOR_CACHE_TTL=60000\n\n# Rate limit: max calls per minute (default: 30)\nLLM_EVALUATOR_RATE_LIMIT=30"}],"\n",["$","h2",null,{"id":"the-three-evaluators","children":["$","a",null,{"href":"#the-three-evaluators","className":"anchor-link","children":"The Three Evaluators"}]}],"\n",["$","h3",null,{"id":"1-mood-evaluator","children":["$","a",null,{"href":"#1-mood-evaluator","className":"anchor-link","children":"1. Mood Evaluator"}]}],"\n",["$","p",null,{"children":"Analyzes user messages for emotional content and suggests appropriate mood shifts."}],"\n",["$","$Lf",null,{"language":"javascript","children":"import { evaluateMood } from './services/llmEvaluator.js';\n\nconst result = await evaluateMood(\"omg you're so cute!\", {\n  relationshipStage: 'friend',\n  currentMood: 'neutral'\n});\n\n// Result:\n{\n  sentiment: 0.8,\n  dominantEmotion: \"happy\",\n  suggestedMood: \"flustered\",\n  moodConfidence: 0.92,\n  triggerReason: \"received_compliment\",\n  detectedPatterns: {\n    isChallenge: false,\n    isCompliment: true,\n    isPlayful: false,\n    isVulnerable: false,\n    isRude: false,\n    isSarcastic: false\n  }\n}"}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Used by:"}]," ",["$","code",null,{"children":"personality.js"}]," → ",["$","code",null,{"children":"processInteraction()"}]]}],"\n",["$","h3",null,{"id":"2-relationship-evaluator","children":["$","a",null,{"href":"#2-relationship-evaluator","className":"anchor-link","children":"2. Relationship Evaluator"}]}],"\n",["$","p",null,{"children":"Assesses interaction quality and determines appropriate relationship changes."}],"\n",["$","$Lf",null,{"language":"javascript","children":"import { evaluateRelationship } from './services/llmEvaluator.js';\n\nconst result = await evaluateRelationship(\n  \"I've been having a really tough week...\",\n  \"Hey... I'm not good at this stuff, but... I'm here. You can talk to me, okay?\",\n  {\n    stage: 'friend',\n    affection: 0.5,\n    trust: 0.4,\n    familiarity: 0.6,\n    rivalry: 0.1\n  }\n);\n\n// Result:\n{\n  interactionQuality: \"deep\",\n  emotionalDepth: 0.85,\n  trustIndicators: {\n    sharedVulnerability: true,\n    askedForHelp: true,\n    showedCare: true,\n    wasHonest: true\n  },\n  relationshipDeltas: {\n    affection: 0.04,\n    trust: 0.03,\n    familiarity: 0.02,\n    rivalry: 0\n  },\n  suggestedInsideJoke: null,\n  noteworthyMoment: \"User opened up about having a tough week\",\n  reasoning: \"Deep emotional moment with vulnerability and care shown\"\n}"}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Used by:"}]," ",["$","code",null,{"children":"personality.js"}]," → ",["$","code",null,{"children":"processInteraction()"}]]}],"\n",["$","h3",null,{"id":"3-jarvis-intent-parser","children":["$","a",null,{"href":"#3-jarvis-intent-parser","className":"anchor-link","children":"3. Jarvis Intent Parser"}]}],"\n",["$","p",null,{"children":"Parses natural language admin commands into structured actions."}],"\n",["$","$Lf",null,{"language":"javascript","children":"import { parseJarvisIntent } from './services/llmEvaluator.js';\n\nconst result = await parseJarvisIntent(\"yo give @CoolUser like 100 coins\", {\n  recentCommands: ['user_info'],\n  userId: '123456789'\n});\n\n// Result:\n{\n  isCommand: true,\n  command: \"give_bebits\",\n  confidence: 0.88,\n  params: {\n    targetUserId: \"987654321\",\n    amount: 100,\n    text: null\n  },\n  requiresConfirmation: false,\n  clarificationNeeded: null,\n  reasoning: \"'yo give' indicates giving, 'like 100 coins' = 100 bebits\"\n}"}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Used by:"}]," ",["$","code",null,{"children":"adminCommands.js"}]," → ",["$","code",null,{"children":"parseAndExecuteAdminCommand()"}]]}],"\n",["$","h2",null,{"id":"rate-limiting","children":["$","a",null,{"href":"#rate-limiting","className":"anchor-link","children":"Rate Limiting"}]}],"\n",["$","p",null,{"children":"The evaluator implements a sliding window rate limiter:"}],"\n",["$","$Lf",null,{"language":"javascript","children":"// 30 calls per minute window\nconst RATE_LIMIT_CALLS = 30;\nconst RATE_LIMIT_WINDOW = 60000; // 1 minute\n\n// If rate limited, returns null (signals fallback)\nif (!checkRateLimit()) {\n  console.log('[LLM_EVALUATOR] Rate limited, using fallback');\n  return null;\n}"}],"\n",["$","h3",null,{"id":"monitoring-rate-limits","children":["$","a",null,{"href":"#monitoring-rate-limits","className":"anchor-link","children":"Monitoring Rate Limits"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"import { getCacheStats } from './services/llmEvaluator.js';\n\nconst stats = getCacheStats();\n// { size: 15, rateLimitCalls: 12, rateLimitRemaining: 18 }"}],"\n",["$","h2",null,{"id":"response-caching","children":["$","a",null,{"href":"#response-caching","className":"anchor-link","children":"Response Caching"}]}],"\n",["$","p",null,{"children":"Responses are cached by content hash to reduce API calls:"}],"\n",["$","$Lf",null,{"language":"javascript","children":"// Cache key is hash of input content\nconst cacheKey = `mood_${hashContent(message + relationshipStage + currentMood)}`;\n\n// Cached responses are reused within TTL\nconst cached = responseCache.get(cacheKey);\nif (cached && Date.now() - cached.timestamp < CACHE_TTL) {\n  return cached.response;\n}"}],"\n",["$","h3",null,{"id":"cache-management","children":["$","a",null,{"href":"#cache-management","className":"anchor-link","children":"Cache Management"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"import { clearCache, getCacheStats } from './services/llmEvaluator.js';\n\n// Check cache status\nconst stats = getCacheStats();\nconsole.log(`Cache size: ${stats.size} entries`);\n\n// Clear if needed\nclearCache();"}],"\n",["$","h2",null,{"id":"fallback-behavior","children":["$","a",null,{"href":"#fallback-behavior","className":"anchor-link","children":"Fallback Behavior"}]}],"\n",["$","p",null,{"children":["When the LLM evaluator is unavailable or returns ",["$","code",null,{"children":"null"}],", each system has fallbacks:"]}],"\n",["$","h3",null,{"id":"mood-fallback","children":["$","a",null,{"href":"#mood-fallback","className":"anchor-link","children":"Mood Fallback"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"// Falls back to keyword matching\nconst positiveWords = ['love', 'thanks', 'awesome', 'great', 'amazing'];\nconst negativeWords = ['hate', 'stupid', 'dumb', 'annoying'];"}],"\n",["$","h3",null,{"id":"relationship-fallback","children":["$","a",null,{"href":"#relationship-fallback","className":"anchor-link","children":"Relationship Fallback"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"// Falls back to fixed deltas\nconst relUpdates = {\n  familiarity: 0.01,\n  affection: sentiment > 0 ? 0.005 : -0.002,\n  trust: isVulnerable ? 0.02 : 0.002\n};"}],"\n",["$","h3",null,{"id":"jarvis-fallback","children":["$","a",null,{"href":"#jarvis-fallback","className":"anchor-link","children":"Jarvis Fallback"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"// Falls back to regex pattern matching\nfor (const pattern of cmd.patterns) {\n  const match = message.match(pattern);\n  if (match) return { command: cmd.name, match };\n}"}],"\n",["$","h2",null,{"id":"error-handling","children":["$","a",null,{"href":"#error-handling","className":"anchor-link","children":"Error Handling"}]}],"\n",["$","p",null,{"children":"The evaluator gracefully handles errors:"}],"\n",["$","$Lf",null,{"language":"javascript","children":"try {\n  const response = await fetch(OPENROUTER_API, { ... });\n\n  if (!response.ok) {\n    console.error('[LLM_EVALUATOR] API error:', response.status);\n    return null;  // Signal fallback\n  }\n\n  // Parse and return\n  return JSON.parse(content);\n\n} catch (error) {\n  console.error('[LLM_EVALUATOR] Error:', error.message);\n  return null;  // Signal fallback\n}"}],"\n",["$","h2",null,{"id":"api-details","children":["$","a",null,{"href":"#api-details","className":"anchor-link","children":"API Details"}]}],"\n",["$","h3",null,{"id":"request-structure","children":["$","a",null,{"href":"#request-structure","className":"anchor-link","children":"Request Structure"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"await fetch('https://openrouter.ai/api/v1/chat/completions', {\n  method: 'POST',\n  headers: {\n    'Authorization': `Bearer ${config.OPENROUTER_API_KEY}`,\n    'Content-Type': 'application/json',\n    'HTTP-Referer': 'https://github.com/CMLKevin/beboa_evo',\n    'X-Title': 'Beboa Discord Bot - LLM Evaluator'\n  },\n  body: JSON.stringify({\n    model: 'x-ai/grok-4.1-fast',\n    messages: [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ],\n    temperature: 0.1,           // Deterministic\n    max_tokens: 500,\n    response_format: { type: 'json_object' }\n  })\n});"}],"\n",["$","h3",null,{"id":"why-grok-41-fast","children":["$","a",null,{"href":"#why-grok-41-fast","className":"anchor-link","children":["Why ",["$","code",null,{"children":"grok-4.1-fast"}],"?"]}]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Fast"}],": Low latency for real-time evaluation"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Cost-effective"}],": Affordable for frequent calls"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"JSON-capable"}],": Reliable structured output"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Context-aware"}],": Understands nuance and sarcasm"]}],"\n"]}],"\n",["$","h2",null,{"id":"debugging","children":["$","a",null,{"href":"#debugging","className":"anchor-link","children":"Debugging"}]}],"\n",["$","p",null,{"children":"Console logs show which evaluation method is used:"}],"\n",["$","$Lf",null,{"language":"$undefined","children":"# LLM evaluation active\n[PERSONALITY] Using LLM mood analysis\n[PERSONALITY] Using LLM relationship eval: meaningful\n[JARVIS] LLM parsed: give_bebits (confidence: 0.92)\n\n# Fallback active\n[PERSONALITY] Using keyword fallback for mood analysis\n[PERSONALITY] Using fallback relationship deltas\n[JARVIS] LLM not available or low confidence, trying pattern matching"}],"\n",["$","h2",null,{"id":"cost-estimation","children":["$","a",null,{"href":"#cost-estimation","className":"anchor-link","children":"Cost Estimation"}]}],"\n",["$","p",null,{"children":["With ",["$","code",null,{"children":"x-ai/grok-4.1-fast"}],":"]}],"\n",["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Usage"}],["$","th",null,{"children":"Calls/Day"}],["$","th",null,{"children":"Est. Cost/Month"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"Light"}],["$","td",null,{"children":"~100"}],["$","td",null,{"children":"~$1-2"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Medium"}],["$","td",null,{"children":"~500"}],["$","td",null,{"children":"~$5-10"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Heavy"}],["$","td",null,{"children":"~2000"}],["$","td",null,{"children":"~$20-40"}]]}]]}]]}],"\n",["$","p",null,{"children":"Caching significantly reduces actual API calls."}],"\n",["$","h2",null,{"id":"best-practices","children":["$","a",null,{"href":"#best-practices","className":"anchor-link","children":"Best Practices"}]}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Monitor rate limits"}]," - Check ",["$","code",null,{"children":"getCacheStats()"}]," regularly"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Trust the fallbacks"}]," - They work when LLM is unavailable"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Keep cache TTL reasonable"}]," - 60s balances freshness vs. cost"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Use low temperature"}]," - 0.1 ensures consistent evaluations"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Check logs"}]," - Verify which method is being used"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Don't disable unnecessarily"}]," - LLM evaluation is superior to keywords"]}],"\n"]}],"\n",["$","h2",null,{"id":"file-location","children":["$","a",null,{"href":"#file-location","className":"anchor-link","children":"File Location"}]}],"\n",["$","$Lf",null,{"language":"$undefined","children":"src/services/llmEvaluator.js"}],"\n",["$","h2",null,{"id":"exports","children":["$","a",null,{"href":"#exports","className":"anchor-link","children":"Exports"}]}],"\n",["$","$Lf",null,{"language":"javascript","children":"// Evaluators\nexport async function evaluateMood(message, context)\nexport async function evaluateRelationship(userMessage, botResponse, context)\nexport async function parseJarvisIntent(message, context)\n\n// Utilities\nexport function isAvailable()     // Check if evaluator can be called\nexport function getCacheStats()   // Get cache and rate limit info\nexport function clearCache()      // Clear response cache"}]]
